{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udfc1 Wrap-up quiz 3\n",
    "\n",
    "This notebook contains the guided project to answer the hands-on questions\n",
    "corresponding to the module \"Hyperparameter tuning\" of the Associate\n",
    "Practitioner Course. In this test **we do not have access to your code**. Only\n",
    "it's output is evaluated by using the multiple choice questions, to be\n",
    "answered in the dedicated User Interface.\n",
    "\n",
    "First run the following cell to initialize jupyterlite. Notice that only basic\n",
    "libraries are available, such as pandas, matplotlib, seaborn and numpy.\n",
    "Remember that the initial import of libraries can take longer than usual, it\n",
    "may take around 10-20 seconds for the following cell to run. Please be\n",
    "patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn==0.13.2\n",
    "import matplotlib\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `penguins.csv` dataset with the following cell of code. The column\n",
    "\"Species\" contains the target variable. We extract the numerical columns that\n",
    "quantify some attributes of such animals and our goal is to predict their\n",
    "species based on those attributes stored in the dataframe named data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "penguins = pd.read_csv(\"../datasets/penguins.csv\")\n",
    "\n",
    "columns = [\"Body Mass (g)\", \"Flipper Length (mm)\", \"Culmen Length (mm)\"]\n",
    "target_name = \"Species\"\n",
    "\n",
    "# Remove lines with missing values for the columns of interest\n",
    "penguins_non_missing = penguins[columns + [target_name]].dropna()\n",
    "\n",
    "data = penguins_non_missing[columns]\n",
    "target = penguins_non_missing[target_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the loaded data to select the correct assertions:\n",
    "\n",
    "Inspect the target variable and select the correct assertions from the\n",
    "following proposals.\n",
    "\n",
    "- a) The problem to be solved is a regression problem\n",
    "- b) The problem to be solved is a binary classification problem\n",
    "  (exactly 2 possible classes)\n",
    "- c) The problem to be solved is a multiclass classification problem\n",
    "  (more than 2 possible classes)\n",
    "\n",
    "_Select a single answer_\n",
    "\n",
    "Hint: `target.nunique()`is a helpful method to answer to this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the statistics of the target and individual features to select the\n",
    "correct statements.\n",
    "\n",
    "- a) The proportions of the class counts are balanced: there are approximately\n",
    "  the same number of rows for each class\n",
    "- b) The proportions of the class counts are imbalanced: some classes have\n",
    "  more than twice as many rows than others\n",
    "- c) The input features have similar scales (ranges of values)\n",
    "\n",
    "_Select all answers that apply_\n",
    "\n",
    "Hint: `data.describe()`, and `target.value_counts()` are methods that are\n",
    "helpful to answer to this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now consider the following pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", StandardScaler()),\n",
    "    (\"classifier\", KNeighborsClassifier(n_neighbors=5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the pipeline using stratified 10-fold cross-validation with the\n",
    "`balanced-accuracy` scoring metric to choose the correct statement in the list\n",
    "below.\n",
    "\n",
    "You can use:\n",
    "\n",
    "- [`sklearn.model_selection.cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html)\n",
    "  to perform the cross-validation routine;\n",
    "- provide an integer `10` to the parameter `cv` of `cross_validate` to use the\n",
    "  cross-validation with 10 folds;\n",
    "- provide the string `\"balanced_accuracy\"` to the parameter `scoring` of\n",
    "  `cross_validate`.\n",
    "\n",
    "- a) The average cross-validated test balanced accuracy of the above pipeline\n",
    "  is between 0.9 and 1.0\n",
    "- b) The average cross-validated test balanced accuracy of the above pipeline\n",
    "  is between 0.8 and 0.9\n",
    "- c) The average cross-validated test balanced accuracy of the above pipeline\n",
    "  is between 0.5 and 0.8\n",
    "\n",
    "_Select a single answer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the evaluation by setting the parameters in order to select the correct\n",
    "statements in the list below. We recall that you can use `model.get_params()`\n",
    "to list the parameters of the pipeline and use\n",
    "`model.set_params(param_name=param_value)` to update them.\n",
    "\n",
    "Remember that one way to compare two models is comparing the cross-validation\n",
    "test scores of both models fold-to-fold, i.e. counting the number of folds\n",
    "where one model has a better test score than the other.\n",
    "\n",
    "Looking at the individual cross-validation scores:\n",
    "\n",
    "- a) Using a model with `n_neighbors=5` is substantially better (at least 7 of\n",
    "  the cross-validations scores are strictly better) than a model with\n",
    "  `n_neighbors=51`\n",
    "- b) Using a model with `n_neighbors=5` is substantially better (at least 7 of\n",
    "  the cross-validations scores are strictly better) than a model with\n",
    "  `n_neighbors=101`\n",
    "- c) A 5 nearest neighbors using a `StandardScaler` is substantially better\n",
    "  (at least 7 of the cross-validations scores are strictly better) than a 5\n",
    "  nearest neighbors using the raw features (without scaling).\n",
    "\n",
    "_Select all answers that apply_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now study the impact of different preprocessors defined in the list below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "\n",
    "all_preprocessors = [\n",
    "    None,\n",
    "    StandardScaler(),\n",
    "    MinMaxScaler(),\n",
    "    QuantileTransformer(n_quantiles=100),\n",
    "    PowerTransformer(method=\"box-cox\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">The Box-Cox method is a common preprocessing strategy for positive values.\n",
    "The other preprocessors work for any kind of numerical features. If you are\n",
    "curious to read more about those methods, feel free to visit the\n",
    "<a class=\"reference external\" href=\"https://scikit-learn.org/stable/modules/preprocessing.html\">preprocessing section of the user\n",
    "guide</a>, although\n",
    "that is not necessary to answer the following questions.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sklearn.model_selection.GridSearchCV` to study the impact of the choice\n",
    "of the preprocessor and the number of neighbors on the stratified 10-fold\n",
    "cross-validated `balanced_accuracy` metric. We want to study the `n_neighbors`\n",
    "in the range `[5, 51, 101]` and `preprocessor` in the range\n",
    "`all_preprocessors`. Although we wouldn't do this in a real setting (and\n",
    "prefer using nested cross validation), for this question, do the\n",
    "cross-validation on the entire dataset.\n",
    "\n",
    "Which of the following statements hold:\n",
    "\n",
    "- a) Looking at the individual cross-validation scores, the best ranked model\n",
    "  using a `StandardScaler` is substantially better (at least 7 of the\n",
    "  cross-validations scores are strictly better) than using any other\n",
    "  preprocessor\n",
    "- b) Using any of the preprocessors has always a better ranking than using no\n",
    "  preprocessor, irrespective of the value `of n_neighbors`\n",
    "- c) Looking at the individual cross-validation scores, the model with\n",
    "  `n_neighbors=5` and `StandardScaler` is substantially better (at least 7 of\n",
    "  the cross-validations scores are strictly better) than the model with\n",
    "  `n_neighbors=51` and `StandardScaler`\n",
    "- d) Looking at the individual cross-validation scores, the model with\n",
    "  `n_neighbors=51` and `StandardScaler` is substantially better (at least 7 of\n",
    "  the cross-validations scores are strictly better) than the model with\n",
    "  `n_neighbors=101` and `StandardScaler`\n",
    "\n",
    "_Select all answers that apply_\n",
    "\n",
    "Hint: pass `{\"preprocessor\": all_preprocessors, \"classifier__n_neighbors\": [5,\n",
    "51, 101]}` for the `param_grid` argument to the `GridSearchCV` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the generalization performance of the best models found in each fold\n",
    "using nested cross-validation. Set `return_estimator=True` and `cv=10` for the\n",
    "outer loop. The scoring metric must be the `balanced-accuracy`. The mean\n",
    "generalization performance is\n",
    "\n",
    "- a) better than 0.97\n",
    "- b) between 0.92 and 0.97\n",
    "- c) below 0.92\n",
    "\n",
    "_Select a single answer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Explore the set of best parameters that the different grid search models found\n",
    "in each fold of the outer cross-validation. Remember that you can access them\n",
    "with the `best_params_` attribute of the estimator. Select all the statements\n",
    "that are true.\n",
    "\n",
    "- a) The tuned number of nearest neighbors is stable across folds\n",
    "- b) The tuned number of nearest neighbors changes often across folds\n",
    "- c) The optimal scaler is stable across folds\n",
    "- d) The optimal scaler changes often across folds\n",
    "\n",
    "_Select all answers that apply_\n",
    "\n",
    "Hint: it is important to pass `return_estimator=True` to the `cross_validate`\n",
    "function to be able to introspect trained model saved in the `\"estimator\"`\n",
    "field of the CV results. If you forgot to do for the previous question, please\n",
    "re-run the cross-validation with that option enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}